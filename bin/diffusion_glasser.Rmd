---
title: "diffusion"
author: "nforde"
date: "March 13, 2018"
output: html_document
---

## get libraries/set paths
```{r}
library(igraph)
library(dplyr)
library(tidyr)
library(ggplot2)
library(broom)
library(knitr)
library(car)
library(rmarkdown)
library(lme4)
library(multcomp)

threshold = 5 #percent threshold value, keeps this percent of connections

## set all the paths
pond_demographics <- read.csv("/projects/stephanie/DataFiles_CT.DTI.Beh.POND/GlimExtIN_CTROIUF.csv")
qap_functional_temporal <- read.csv("/mnt/tigrlab/projects/edickie/analysis/POND_RST/qap/qap_functional_temporal.csv")
tsdir <- "/scratch/nforde/homotopic/POND/hcp/glasser_meants"
diffdir <- "/scratch/nforde/homotopic/POND/CSD"
ts_pattern <- "RST_pond42fix"

pond_extra <- read.csv("/scratch/nforde/homotopic/POND/pond_demog.csv")


for (i in 1:nrow(pond_extra)) {
  if (startsWith(as.character(pond_extra$subject[i]), "88")) {
    pond_extra$subject[i] <- paste0("0", pond_extra$subject[i])
  }
}
z <-  strsplit(as.character(pond_demographics$DTI.CT.codes),"-")
pond_demographics$subject <- sapply(z,FUN=function(x){paste0(x[1],x[2])})
demogs <- merge(pond_demographics, pond_extra[c(1,2,7:10,12)], by.x="subject", by.y="subject", all.x=TRUE)
demogs <- demogs[!duplicated(demogs$subject),]

```
## define functions
```{r}

## for normalising data
transform_to_normal <- function(X) {
  # calculate the best exponent using powerTransform:
  pT <- powerTransform(X)
  # apply the power transform and save the result to a new variable
  X_pT <- X^pT$lambda ## note ^ is exponent in r
  return(X_pT)
}

## to make dataframe that labels connection as I, HE and HO
make_g_template <- function(subid, tsdir, ts_pattern) {
  meants <- read.csv(file.path(tsdir,
                               paste(subid, ts_pattern, "glasser_meants.csv", sep="_")),
                     header=FALSE)  

  roiids <- read.csv(file.path(tsdir,
                               paste(subid, ts_pattern, "glasser_roiids.csv", sep="_")),
                     header=TRUE)  
  
  rois <- as.character(roiids$labelname)
  meants_t <- t(meants)
  colnames(meants_t) <- rois
  
  cormat <- cor(meants_t)
  g<-graph_from_adjacency_matrix(cormat,mode="upper", 
                                 weighted=T, diag=F, 
                                 add.rownames = "code")
  g.df <- as.data.frame(get.edgelist(g), names=T)

  #split ROI names into hemi and name  
  for (i in 1:nrow(g.df)) {
    g.df$V1.hemi[i] = strsplit(as.character(g.df$V1[i]),"_")[[1]][1]
    g.df$V1.roi[i] = strsplit(as.character(g.df$V1[i]),"_")[[1]][2]
    g.df$V2.hemi[i] = strsplit(as.character(g.df$V2[i]),"_")[[1]][1]
    g.df$V2.roi[i] = strsplit(as.character(g.df$V2[i]),"_")[[1]][2]
  }
  
  g.df$FCtype <- NA
  g.df$FCtype[g.df$V1.roi==g.df$V2.roi & g.df$V1.hemi!=g.df$V2.hemi] <- "Homotopic"
  g.df$FCtype[g.df$V1.roi!=g.df$V2.roi & g.df$V1.hemi!=g.df$V2.hemi] <- "Heterotopic"
  g.df$FCtype[g.df$V1.roi!=g.df$V2.roi & g.df$V1.hemi==g.df$V2.hemi] <- "Intrahemispheric"
  
  return(g.df)
  
}


## to calculate diffusion connection weight for each connection type (HO, HE, I, CC)
calc_diff <- function(subids, diffdir, g.df, percent_threshold) {
  
  ## use these parameters to set up a black dataframe to hold all the correlations
  theZs <- data.frame("subid" = subids, 
                      "HO" = numeric(length(subids)),
                      "HE" = numeric(length(subids)),
                      "I" = numeric(length(subids)),
                      "len1" = numeric(length(subids)),
                      "len2" = numeric(length(subids)),
                      "len3" = numeric(length(subids)),
                      "len4" = numeric(length(subids)),
                      "len5" = numeric(length(subids)),
                      "len6" = numeric(length(subids)),
                      "len7" = numeric(length(subids)),
                      "len8" = numeric(length(subids)),
                      "len9" = numeric(length(subids)),
                      "len10" = numeric(length(subids)),
                      "len11" = numeric(length(subids)),
                      "len12" = numeric(length(subids)),
                      "len13" = numeric(length(subids)),
                      "len14" = numeric(length(subids)),
                      "len15" = numeric(length(subids)),
                      "len16" = numeric(length(subids)),
                      "len17" = numeric(length(subids)),
                      "len18" = numeric(length(subids)),
                      "len19" = numeric(length(subids)),
                      "len20" = numeric(length(subids)))
                      
  theZs[ ,2:ncol(theZs)] <- numeric(nrow(theZs)*(ncol(theZs)-1))
  
  roiids <- read.csv("/scratch/nforde/homotopic/atlases/roiids.csv", sep="," , header=TRUE)
  
  ## now get everyones diff connectivity matrix and voxel count 
  for (i in 1:nrow(theZs)) {
    ## get the subid from the dataframe and read in the diff
    subid <- theZs$subid[i]
    diff.file <- file.path(diffdir, subid, "det_connectome.csv")
    len.file <- file.path(diffdir, subid, "det_length_connectome.csv")
    vox.file <- file.path(diffdir, subid, "voxel_count.txt")                         
    
    if (file.exists(diff.file)) {
      diff <- read.csv(diff.file, sep="", header=FALSE) 
      
      rois <- as.character(roiids$labelname)
      colnames(diff) <- rois
      rownames(diff) <- rois
      
      #can't have 0's for igraph : +1, make graph merge and then -1
      diffplus1 <-diff +1
      diff_g<-graph_from_adjacency_matrix(as.matrix(diffplus1),mode="upper", 
                                    weighted=T, diag=F, add.colnames=T) 
     # take the egde list as a vector
      rawplus1 <- E(diff_g)$weight
      raw <- rawplus1 -1
      edges.df <- cbind(g.df, raw)
      
      #normalise for number of voxels 
      vox <- read.table(vox.file, sep="", header=FALSE)
      oddvals <- seq(1, ncol(vox), by=2)
      vox_count <- vox[,oddvals] #select voxel number and exclude volume
      t.vox <- t(vox_count)
      voxels <- data.frame(t.vox, rois)
      colnames(voxels) <- c('vox', 'rois')
      
      edges <- edges.df[c('V1','V2')]
      V1.vox <- merge(edges, voxels, by.x='V1', by.y='rois')
      V2.vox <- merge(edges, voxels, by.x='V2', by.y='rois')
      V1.V2 <- merge(V1.vox, V2.vox, by=c('V1', 'V2'))
      V1.V2$vox.total <- as.numeric(V1.V2$vox.x) + as.numeric(V1.V2$vox.y)
      edges_w <- merge(edges.df, V1.V2[c(1,2,5)], by=c('V1', 'V2'))
      edges_w$weight <- edges_w$raw / edges_w$vox.total * (sum(edges_w$vox.total)/64620)
      
      #length connectome
      len <- read.csv(len.file, sep="", header=FALSE)
      colnames(len) <- rois
      rownames(len) <- rois
      #can't have 0's for igraph : +1, make graph merge and then -1
      lenplus1 <-len +1
      len_g<-graph_from_adjacency_matrix(as.matrix(lenplus1),mode="upper", 
                                    weighted=T, diag=F, add.colnames=T) 
      #take the egde list as a vector
      lenplus1 <- E(len_g)$weight
      length <- lenplus1 -1
      len.df <- cbind(g.df, length)
      edges_w_l <- merge(edges_w, len.df[c(1,2,8)], by=c('V1', 'V2'))
      
      #select nonzero length connections and bin 
      edges_wl_nonzero <- subset(edges_w_l, length > 0)
      edges_wl_nonzero <- within(edges_wl_nonzero, len_quant <- as.integer(cut(length, quantile(length, probs=0:20/20), include.lowest=TRUE)))
      
      #can merge to get full edge list again
     # edges_wlq <- merge(edges_w_l, edges_wl_nonzero[c(1,2,12)], by=c('V1', 'V2'), all.x=TRUE)
      
      #threshold by connection weight to remove spurious connections .....%
     # edges_thresh <- subset(edges_wlq, weight > quantile(weight, prob = 1 - percent_threshold/100))
      
      # calculate averages for Ho, He & I & write to df
      theZs$HO[i] <- mean(filter(edges_wl_nonzero, FCtype == "Homotopic")$weight)
      theZs$HE[i] <- mean(filter(edges_wl_nonzero, FCtype == "Heterotopic")$weight)
      theZs$I[i] <- mean(filter(edges_wl_nonzero, FCtype == "Intrahemispheric")$weight)
      theZs$len1[i] <- mean(filter(edges_wl_nonzero, len_quant == "1")$weight)
      theZs$len2[i] <- mean(filter(edges_wl_nonzero, len_quant == "2")$weight)
      theZs$len3[i] <- mean(filter(edges_wl_nonzero, len_quant == "3")$weight)
      theZs$len4[i] <- mean(filter(edges_wl_nonzero, len_quant == "4")$weight)
      theZs$len5[i] <- mean(filter(edges_wl_nonzero, len_quant == "5")$weight)
      theZs$len6[i] <- mean(filter(edges_wl_nonzero, len_quant == "6")$weight)
      theZs$len7[i] <- mean(filter(edges_wl_nonzero, len_quant == "7")$weight)
      theZs$len8[i] <- mean(filter(edges_wl_nonzero, len_quant == "8")$weight)
      theZs$len9[i] <- mean(filter(edges_wl_nonzero, len_quant == "9")$weight)
      theZs$len10[i] <- mean(filter(edges_wl_nonzero, len_quant == "10")$weight)
      theZs$len11[i] <- mean(filter(edges_wl_nonzero, len_quant == "11")$weight)
      theZs$len12[i] <- mean(filter(edges_wl_nonzero, len_quant == "12")$weight)
      theZs$len13[i] <- mean(filter(edges_wl_nonzero, len_quant == "13")$weight)
      theZs$len14[i] <- mean(filter(edges_wl_nonzero, len_quant == "14")$weight)
      theZs$len15[i] <- mean(filter(edges_wl_nonzero, len_quant == "15")$weight)
      theZs$len16[i] <- mean(filter(edges_wl_nonzero, len_quant == "16")$weight)
      theZs$len17[i] <- mean(filter(edges_wl_nonzero, len_quant == "17")$weight)
      theZs$len18[i] <- mean(filter(edges_wl_nonzero, len_quant == "18")$weight)
      theZs$len19[i] <- mean(filter(edges_wl_nonzero, len_quant == "19")$weight)
      theZs$len20[i] <- mean(filter(edges_wl_nonzero, len_quant == "20")$weight)     
      
    } else {
      print(paste(diff.file, "does not exist"))
      theZs[i,2:ncol(theZs)] <- NA
    }
  }
  return(theZs)
}

```
## Run POND
```{r}
demogs$subid <- paste0("MR160-",demogs$DTI.CT.codes)
demogs <- merge(demogs, qap_functional_temporal, by.x = "subid", by.y = "subject")
demogs <- filter(demogs, perc_fd < 5)

## transform QC measures to normality
# demogs <- demogs %>%
#   mutate("dvars_pT"  = transform_to_normal(dvars),
#          "m_tsnr_pT"  = transform_to_normal(m_tsnr),
#          "mean_fd_pT"  = transform_to_normal(mean_fd),
#          "quality_pT" = transform_to_normal(quality))

# ## Now lets do a PCA on the QAP numbers...
# # Pricipal Components Analysis
# # entering raw data and extracting PCs
# # from the correlation matrix
# fit <- princomp(dplyr::select(demogs, dvars_pT, m_tsnr_pT, mean_fd_pT, quality_pT) , cor=TRUE)
# summary(fit) # print variance accounted for
# loadings(fit) # pc loadings
# plot(fit,type="lines") # scree plot
# ## write the top 5 principal components to the speadsheet
# demogs <- cbind(demogs,fit$scores[ ,1:2]) # the principal components

subids <- demogs$subid

g.df <- make_g_template(subids[1], tsdir, ts_pattern)

pond_Zs <- calc_diff(subids, diffdir, g.df, threshold)

```

## plot diff weight with QC measures
```{r, fig.width=12}

 PONDdemZs <- merge(pond_Zs,demogs,by="subid") %>%
   gather(FCtype, Z, HO, HE, I) %>%
   filter(NDD != "", !is.na(Z))
  
PONDdemLs <- merge(pond_Zs,demogs,by="subid") %>%
   gather(lenQ, Z, starts_with("len")) %>%
   filter(NDD != "", !is.na(Z))

# ggplot(PONDdemZs, aes(x=Comp.1, y=Z , color = NDD)) + 
#   geom_point() + geom_smooth(method = "lm") +
#   facet_wrap(~FCtype)
# 
# ggplot(PONDdemZs, aes(x=Comp.2, y=Z , color = NDD)) + 
#   geom_point() + geom_smooth(method = "lm") +
#   facet_wrap(~FCtype)
# 
# resids <- PONDdemZs %>%
#   #group_by(FCtype) %>%
#   do(augment(lm(Z ~ Comp.1 + Comp.2, data = .)))
# names(resids) <- paste0('QC',names(resids))
# 
# PONDdemZs1 <- cbind(PONDdemZs, as.data.frame(resids))
# 
# ggplot(PONDdemZs1, aes(x=Age, y=QC.resid , color = NDD)) + 
#   geom_point() + geom_smooth(method = "lm") +
#   facet_grid(NDD~FCtype)
# 
# ggplot(PONDdemZs1, aes(x=Age, y=QC.resid , color = NDD)) + 
#   geom_point() + geom_smooth(method = "lm") +
#   facet_wrap(~FCtype)

#simplified_pond <- PONDdemZs1 %>%
#  filter(Age > 6, Age < 18, NDD != "HC")

simplified_pond <- PONDdemZs %>%
  filter(Age > 6, Age < 18)

simplified_pondL <- PONDdemLs %>%
  filter(Age > 6, Age < 18)


# ggplot(simplified_pond, aes(x=Age, y=QC.resid , color = NDD)) + 
#   geom_point() + geom_smooth(method = "lm") +
#   facet_wrap(~FCtype)
# 
# ggplot(simplified_pond, aes(x=NDD, y=QC.resid, color = NDD)) +
#   geom_boxplot() + geom_jitter() +
#   facet_wrap(~FCtype)
# 
# ggplot(simplified_pond, aes(x=Age, y=QC.resid , color = NDD)) + 
#   geom_point() + geom_smooth(method = "lm") +
#   facet_grid(sex~FCtype)
# 
# ggplot(simplified_pond, aes(x=sex, y=QC.resid , color = NDD)) + 
#   geom_boxplot() + 
#   facet_wrap(~FCtype)

```
## statistics DIFFUSION group FCtype
```{r, fig.width=12}
#using Anova (type 2 F tests [unique variance]) instead of aov (type 1 F test [sequential])

# fctype x dx
print(paste("Anova Table for fctype X NDD"))
F2 <- lmer(Z ~ FCtype*NDD + Age + sex + (1|subid), 
               data = simplified_pond)
print(Anova(F2))
summary(glht(F2, linfct=mcp(NDD ="Tukey")))
summary(glht(F2, linfct=mcp(FCtype ="Tukey")))

# plot fctype X dx
ggplot(simplified_pond, aes(x=FCtype, y=Z, color = NDD)) + 
  geom_boxplot() 

# fctype x dx (male only)
print(paste("Anova Table for fctype X NDD, male only"))
F2 <- lmer(Z ~ FCtype*NDD + Age + (1|subid), 
               data = filter(simplified_pond, sex == "Male"))
print(Anova(F2))
summary(glht(F2, linfct=mcp(NDD ="Tukey")))
summary(glht(F2, linfct=mcp(FCtype ="Tukey")))
         
# plot fctype X dx (male only)
ggplot(filter(simplified_pond, sex == "Male"), aes(x=FCtype, y=Z, color = NDD)) + 
  geom_boxplot() 

# dx per fctype
for (fctype in c('HE','HO','I')) {
  print(paste("Anova Table for",fctype))
  F2 <- lm(Z ~ NDD + Age + sex, 
                 data = filter(simplified_pond, FCtype == fctype))
  print(Anova(F2))
  summary(glht(F2, linfct=mcp(NDD ="Tukey")))
}

#male only dx per fctype
for (fctype in c('HE','HO','I')) {
  print(paste("Anova Table for",fctype))
  F2 <- lm(Z ~ NDD + Age,
                 data = filter(simplified_pond, sex == "Male", FCtype == fctype))
  print(Anova(F2))
  summary(glht(F2, linfct=mcp(NDD ="Tukey")))
}


#for (fctype in c("CC01","CC02","CC03","CC04", "CC05","CC06","CC07","CC08","CC09", "CC10")) {
#  print(paste("Anova Table for",fctype))
#  a1 <- aov(Z ~ NDD + Age + Comp.1 + Comp.2, 
#                 data = filter(simplified_pond, sex == "Male", FCtype == fctype))
#  print(summary(a1))
#  print(TukeyHSD(x=a1, 'NDD', conf.level=0.95))
#}

#ggplot(filter(simplified_pond, FCtype %in% c("CC01","CC02","CC03","CC04", "CC05","CC06","CC07","CC08","CC09", "CC10")), 
#       aes(x=as.numeric(factor(FCtype)), y=Z , color = NDD)) + 
# geom_jitter(width = 0.5) + geom_smooth(span = 0.5) 

```

## statistics DIFFUSION Continuous measures FCtype
```{r, fig.width=12}
# ABAS_GC + SCQ + TOCS +FSIQ.x + AttnCBCLR

# fctype x continuous measures
print(paste("Anova Table for fctype with continuous measures"))
F2 <- Anova(lmer(Z ~ FCtype + ABAS_GC*TOCS*AttnCBCLR*SCQ + FSIQ + Age + sex + (1|subid), 
               data = simplified_pond, na.action=na.omit))
print(F2)
F1 <- aov(Z ~ Age + sex + FSIQ + FCtype + ABAS_GC*TOCS*AttnCBCLR*SCQ, 
               data = simplified_pond)
print(TukeyHSD(x=F1, 'FCtype', conf.level=0.95))


# plot adaptive func by type and xx
ggplot(simplified_pond, aes(x=ABAS_GC, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

# plot SCQ by type and xx
ggplot(simplified_pond, aes(x=SCQ, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

# plot TOCS by type and xx
ggplot(simplified_pond, aes(x=TOCS, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

# plot AttnCBCLR by type and xx
ggplot(simplified_pond, aes(x=AttnCBCLR, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

# plot FSIQ by type and xx
ggplot(simplified_pond, aes(x=FSIQ, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

# ####
# # dx per fctype
# for (fctype in c('HE','HO','I')) {
#   print(paste("Anova Table for",fctype))
#   a1 <- aov(Z ~ NDD + Age + sex , 
#                  data = filter(simplified_pond, FCtype == fctype))
#   print(summary(a1))
#   print(TukeyHSD(x=a1, 'NDD', conf.level=0.95))
# }
# 
# #male only dx per fctype
# for (fctype in c('HE','HO','I')) {
#   print(paste("Anova Table for",fctype))
#   a1 <- aov(Z ~ NDD + Age , 
#                  data = filter(simplified_pond, sex == "Male", FCtype == fctype))
#   print(summary(a1))
#   print(TukeyHSD(x=a1, 'NDD', conf.level=0.95))
# }
```

## statistics DIFFUSION group length
```{r, fig.width=12}
#using Anova (type 2 F tests [unique variance]) instead of aov (type 1 F test [sequential])

simplified_pondL$lenQordered <- factor(simplified_pondL$lenQ, c('len1','len2','len3','len4','len5','len6','len7','len8','len9','len10','len11','len12','len13','len14','len15','len16','len17','len18','len19','len20'))

# length x dx
print(paste("Anova Table for length X NDD"))
F2 <- lmer(Z ~ lenQ*NDD + Age + sex + (1|subid), 
               data = simplified_pondL)
print(Anova(F2))
summary(glht(F2, linfct=mcp(NDD ="Tukey")))
#summary(glht(F2, linfct=mcp(lenQ ="Tukey")))

# plot lenQ X dx ### need to get length quantiles in order
ggplot(simplified_pondL, aes(x=lenQordered, y=Z, color = NDD)) + 
  geom_boxplot() 

# lenQ x dx (male only)
print(paste("Anova Table for lenQ X NDD, male only"))
F2 <- lmer(Z ~ lenQ*NDD + Age + (1|subid), 
               data = filter(simplified_pondL, sex == "Male"))
print(Anova(F2))
summary(glht(F2, linfct=mcp(NDD ="Tukey")))
#summary(glht(F2, linfct=mcp(lenQ ="Tukey")))
         
# plot lenQ X dx (male only)
ggplot(filter(simplified_pondL, sex == "Male"), aes(x=lenQordered, y=Z, color = NDD)) + 
  geom_boxplot() 

# # dx per lenQ
# for (lenQ in c('len1','len2','len3','len4','len5','len6','len7','len8','len9','len10','len11','len12','len13','len14','len15','len16','len17','len18','len19','len20')) {
#   print(paste("Anova Table for",lenQ))
#   F2 <- lm(Z ~ NDD + Age + sex, 
#                  data = filter(simplified_pondL, lenQ == lenQ))
#   print(Anova(F2))
#   summary(glht(F2, linfct=mcp(NDD ="Tukey")))
# }
# 
# #male only dx per lenQ
# for (lenQ in c('len1','len2','len3','len4','len5','len6','len7','len8','len9','len10','len11','len12','len13','len14','len15','len16','len17','len18','len19','len20')) {
#   print(paste("Anova Table for",lenQ))
#   F2 <- lm(Z ~ NDD + Age,
#                  data = filter(simplified_pondL, sex == "Male", lenQ == lenQ))
#   print(Anova(F2))
#   summary(glht(F2, linfct=mcp(NDD ="Tukey")))
# }


ggplot(simplified_pondL,aes(x=as.numeric(factor(lenQordered)), y=Z , color = NDD)) + 
  geom_jitter(width = 0.5) + geom_smooth(span = 0.5) 

```