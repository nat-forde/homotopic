---
title: "diffusion"
author: "nforde"
date: "March 13, 2018"
output: html_document
---

## get libraries/set paths
```{r}
library(igraph)
library(dplyr)
library(tidyr)
library(ggplot2)
library(broom)
library(knitr)
library(car)
library(rmarkdown)

threshold = 5 #percent threshold value, keeps this percent of connections

## set all the paths
pond_demographics <- read.csv("/projects/stephanie/DataFiles_CT.DTI.Beh.POND/GlimExtIN_CTROIUF.csv")
qap_functional_temporal <- read.csv("/mnt/tigrlab/projects/edickie/analysis/POND_RST/qap/qap_functional_temporal.csv")
tsdir <- "/scratch/nforde/homotopic/POND/hcp/glasser_meants"
diffdir <- "/scratch/nforde/homotopic/POND/CSD"
ts_pattern <- "RST_pond42fix"

pond_extra <- read.csv("/scratch/nforde/homotopic/POND/pond_demog.csv")


for (i in 1:nrow(pond_extra)) {
  if (startsWith(as.character(pond_extra$subject[i]), "88")) {
    pond_extra$subject[i] <- paste0("0", pond_extra$subject[i])
  }
}
z <-  strsplit(as.character(pond_demographics$DTI.CT.codes),"-")
pond_demographics$subject <- sapply(z,FUN=function(x){paste0(x[1],x[2])})
demogs <- merge(pond_demographics, pond_extra[c(1,2,7:10,12)], by.x="subject", by.y="subject", all.x=TRUE)

```
## define functions
```{r}

## for normalising data
transform_to_normal <- function(X) {
  # calculate the best exponent using powerTransform:
  pT <- powerTransform(X)
  # apply the power transform and save the result to a new variable
  X_pT <- X^pT$lambda ## note ^ is exponent in r
  return(X_pT)
}

## to make dataframe that labels connection as I, HE and HO
make_g_template <- function(subid, tsdir, ts_pattern) {
  meants <- read.csv(file.path(tsdir,
                               paste(subid, ts_pattern, "glasser_meants.csv", sep="_")),
                     header=FALSE)  

  roiids <- read.csv(file.path(tsdir,
                               paste(subid, ts_pattern, "glasser_roiids.csv", sep="_")),
                     header=TRUE)  
  
  rois <- as.character(roiids$labelname)
  meants_t <- t(meants)
  colnames(meants_t) <- rois
  
  cormat <- cor(meants_t)
  g<-graph_from_adjacency_matrix(cormat,mode="upper", 
                                 weighted=T, diag=F, 
                                 add.rownames = "code")
  g.df <- as.data.frame(get.edgelist(g), names=T)

  #split ROI names into hemi and name  
  for (i in 1:nrow(g.df)) {
    g.df$V1.hemi[i] = strsplit(as.character(g.df$V1[i]),"_")[[1]][1]
    g.df$V1.roi[i] = strsplit(as.character(g.df$V1[i]),"_")[[1]][2]
    g.df$V2.hemi[i] = strsplit(as.character(g.df$V2[i]),"_")[[1]][1]
    g.df$V2.roi[i] = strsplit(as.character(g.df$V2[i]),"_")[[1]][2]
  }
  
  g.df$FCtype <- NA
  g.df$FCtype[g.df$V1.roi==g.df$V2.roi & g.df$V1.hemi!=g.df$V2.hemi] <- "Homotopic"
  g.df$FCtype[g.df$V1.roi!=g.df$V2.roi & g.df$V1.hemi!=g.df$V2.hemi] <- "Heterotopic"
  g.df$FCtype[g.df$V1.roi!=g.df$V2.roi & g.df$V1.hemi==g.df$V2.hemi] <- "Intrahemispheric"
  
  return(g.df)
  
}


## to calculate diffusion connection weight for each connection type (HO, HE, I, CC)
calc_diff <- function(subids, diffdir, g.df, percent_threshold) {
  
  ## use these parameters to set up a black dataframe to hold all the correlations
  theZs <- data.frame("subid" = subids, 
                      "HO" = numeric(length(subids)),
                      "HE" = numeric(length(subids)),
                      "I" = numeric(length(subids)),
                      "len1" = numeric(length(subids)),
                      "len2" = numeric(length(subids)),
                      "len3" = numeric(length(subids)),
                      "len4" = numeric(length(subids)),
                      "len5" = numeric(length(subids)),
                      "len6" = numeric(length(subids)),
                      "len7" = numeric(length(subids)),
                      "len8" = numeric(length(subids)),
                      "len9" = numeric(length(subids)),
                      "len10" = numeric(length(subids)),
                      "len11" = numeric(length(subids)),
                      "len12" = numeric(length(subids)),
                      "len13" = numeric(length(subids)),
                      "len14" = numeric(length(subids)),
                      "len15" = numeric(length(subids)),
                      "len16" = numeric(length(subids)),
                      "len17" = numeric(length(subids)),
                      "len18" = numeric(length(subids)),
                      "len19" = numeric(length(subids)),
                      "len20" = numeric(length(subids)))
                      
  theZs[ ,2:ncol(theZs)] <- numeric(nrow(theZs)*(ncol(theZs)-1))
  
  roiids <- read.csv("/scratch/nforde/homotopic/atlases/roiids.csv", sep="," , header=TRUE)
  
  ## now get everyones diff connectivity matrix and voxel count 
  for (i in 1:nrow(theZs)) {
    ## get the subid from the dataframe and read in the diff
    subid <- theZs$subid[i]
    diff.file <- file.path(diffdir, subid[i], "det_connectome.csv")
    len.file <- file.path(diffdir, subid[i], "det_length_connectome.csv")
    vox.file <- file.path(diffdir, subid[i], "voxel_count.txt")                         
    
    if (file.exists(diff.file)) {
      diff <- read.csv(diff.file, sep="", header=FALSE) 
      
      rois <- as.character(roiids$labelname)
      colnames(diff) <- rois
      rownames(diff) <- rois
      
      #can't have 0's for igraph : +1, make graph merge and then -1
      diffplus1 <-diff +1
      diff_g<-graph_from_adjacency_matrix(as.matrix(diffplus1),mode="upper", 
                                    weighted=T, diag=F, add.colnames=T) 
     # take the egde list as a vector
      rawplus1 <- E(diff_g)$weight
      raw <- rawplus1 -1
      edges.df <- cbind(g.df, raw)
      
      #normalise for number of voxels 
      vox <- read.table(vox.file, sep="", header=FALSE)
      oddvals <- seq(1, ncol(vox), by=2)
      vox_count <- vox[,oddvals] #select voxel number and exclude volume
      t.vox <- t(vox_count)
      voxels <- data.frame(t.vox, rois)
      colnames(voxels) <- c('vox', 'rois')
      
      edges <- edges.df[c('V1','V2')]
      V1.vox <- merge(edges, voxels, by.x='V1', by.y='rois')
      V2.vox <- merge(edges, voxels, by.x='V2', by.y='rois')
      V1.V2 <- merge(V1.vox, V2.vox, by=c('V1', 'V2'))
      V1.V2$vox.total <- as.numeric(V1.V2$vox.x) + as.numeric(V1.V2$vox.y)
      edges_w <- merge(edges.df, V1.V2[c(1,2,5)], by=c('V1', 'V2'))
      edges_w$weight <- edges_w$raw / edges_w$vox.total * (sum(edges_w$vox.total)/64620)
      
      #length connectome
      len <- read.csv(len.file, sep="", header=FALSE)
      colnames(len) <- rois
      rownames(len) <- rois
      #can't have 0's for igraph : +1, make graph merge and then -1
      lenplus1 <-len +1
      len_g<-graph_from_adjacency_matrix(as.matrix(lenplus1),mode="upper", 
                                    weighted=T, diag=F, add.colnames=T) 
      #take the egde list as a vector
      lenplus1 <- E(len_g)$weight
      length <- lenplus1 -1
      len.df <- cbind(g.df, length)
      edges_w_l <- merge(edges_w, len.df[c(1,2,8)], by=c('V1', 'V2'))
      
      #select nonzero length connections and bin 
      edges_wl_nonzero <- subset(edges_w_l, length > 0)
      edges_wl_nonzero <- within(edges_wl_nonzero, len_quant <- as.integer(cut(length, quantile(length, probs=0:20/20), include.lowest=TRUE)))
      
      #can merge to get full edge list again
     # edges_wlq <- merge(edges_w_l, edges_wl_nonzero[c(1,2,12)], by=c('V1', 'V2'), all.x=TRUE)
      
      #threshold by connection weight to remove spurious connections .....%
     # edges_thresh <- subset(edges_wlq, weight > quantile(weight, prob = 1 - percent_threshold/100))
      
      # calculate averages for Ho, He & I & write to df
      theZs$HO[i] <- mean(filter(edges_wl_nonzero, FCtype == "Homotopic")$weight)
      theZs$HE[i] <- mean(filter(edges_wl_nonzero, FCtype == "Heterotopic")$weight)
      theZs$I[i] <- mean(filter(edges_wl_nonzero, FCtype == "Intrahemispheric")$weight)
      theZs$len1[i] <- mean(filter(edges_wl_nonzero, len_quant == "1")$weight)
      theZs$len2[i] <- mean(filter(edges_wl_nonzero, len_quant == "2")$weight)
      theZs$len3[i] <- mean(filter(edges_wl_nonzero, len_quant == "3")$weight)
      theZs$len4[i] <- mean(filter(edges_wl_nonzero, len_quant == "4")$weight)
      theZs$len5[i] <- mean(filter(edges_wl_nonzero, len_quant == "5")$weight)
      theZs$len6[i] <- mean(filter(edges_wl_nonzero, len_quant == "6")$weight)
      theZs$len7[i] <- mean(filter(edges_wl_nonzero, len_quant == "7")$weight)
      theZs$len8[i] <- mean(filter(edges_wl_nonzero, len_quant == "8")$weight)
      theZs$len9[i] <- mean(filter(edges_wl_nonzero, len_quant == "9")$weight)
      theZs$len10[i] <- mean(filter(edges_wl_nonzero, len_quant == "10")$weight)
      theZs$len11[i] <- mean(filter(edges_wl_nonzero, len_quant == "11")$weight)
      theZs$len12[i] <- mean(filter(edges_wl_nonzero, len_quant == "12")$weight)
      theZs$len13[i] <- mean(filter(edges_wl_nonzero, len_quant == "13")$weight)
      theZs$len14[i] <- mean(filter(edges_wl_nonzero, len_quant == "14")$weight)
      theZs$len15[i] <- mean(filter(edges_wl_nonzero, len_quant == "15")$weight)
      theZs$len16[i] <- mean(filter(edges_wl_nonzero, len_quant == "16")$weight)
      theZs$len17[i] <- mean(filter(edges_wl_nonzero, len_quant == "17")$weight)
      theZs$len18[i] <- mean(filter(edges_wl_nonzero, len_quant == "18")$weight)
      theZs$len19[i] <- mean(filter(edges_wl_nonzero, len_quant == "19")$weight)
      theZs$len20[i] <- mean(filter(edges_wl_nonzero, len_quant == "20")$weight)     
      
    } else {
      print(paste(diff.file, "does not exist"))
      theZs[i,2:ncol(theZs)] <- NA
    }
  }
  return(theZs)
}

```
## Run POND
```{r}
demogs$subid <- paste0("MR160-",demogs$DTI.CT.codes)
demogs <- merge(demogs, qap_functional_temporal, by.x = "subid", by.y = "subject")
demogs <- filter(demogs, perc_fd < 5)

## transform QC measures to normality
demogs <- demogs %>%
  mutate("dvars_pT"  = transform_to_normal(dvars),
         "m_tsnr_pT"  = transform_to_normal(m_tsnr),
         "mean_fd_pT"  = transform_to_normal(mean_fd),
         "quality_pT" = transform_to_normal(quality))

## Now lets do a PCA on the QAP numbers...
# Pricipal Components Analysis
# entering raw data and extracting PCs
# from the correlation matrix
fit <- princomp(select(demogs, dvars_pT, m_tsnr_pT, mean_fd_pT, quality_pT) , cor=TRUE)
summary(fit) # print variance accounted for
loadings(fit) # pc loadings
plot(fit,type="lines") # scree plot
## write the top 5 principal components to the speadsheet
demogs <- cbind(demogs,fit$scores[ ,1:2]) # the principal components

subids <- demogs$subid

g.df <- make_g_template(subids[1], tsdir, ts_pattern)
## get two variables of interest.. edgenames and the number of edges
myedgenames <- paste(g.df[ ,1],g.df[ ,2],sep=".") ## the V1.V2 name
numedges <- length(myedgenames)                   ## the number of edges
urois <- unique(as.character(g.df$V1.roi))

pond_Zs <- calc_diff(subids, diffdir, g.df, threshold)

```

## plot diff weight with QC measures
```{r, fig.width=12}

PONDdemZs <- merge(pond_Zs,demogs,by="subid") %>%
  gather(FCtype, Z, HO, HE, I, starts_with("CC")) %>%
  filter(NDD != "", !is.na(Z))

ggplot(PONDdemZs, aes(x=Comp.1, y=Z , color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

ggplot(PONDdemZs, aes(x=Comp.2, y=Z , color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

resids <- PONDdemZs %>%
  group_by(FCtype) %>%
  do(augment(lm(Z ~ Comp.1 + Comp.2, data = .)))
names(resids) <- paste0('QC',names(resids))

PONDdemZs1 <- cbind(PONDdemZs, as.data.frame(resids))

ggplot(PONDdemZs1, aes(x=Age, y=QC.resid , color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_grid(NDD~FCtype)

ggplot(PONDdemZs1, aes(x=Age, y=QC.resid , color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

#simplified_pond <- PONDdemZs1 %>%
#  filter(Age > 6, Age < 18, NDD != "HC")
simplified_pond <- PONDdemZs1 %>%
  filter(Age > 6, Age < 18)

ggplot(simplified_pond, aes(x=Age, y=QC.resid , color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)

ggplot(simplified_pond, aes(x=NDD, y=QC.resid, color = NDD)) +
  geom_boxplot() + geom_jitter() +
  facet_wrap(~FCtype)

ggplot(simplified_pond, aes(x=Age, y=QC.resid , color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_grid(sex~FCtype)

ggplot(simplified_pond, aes(x=sex, y=QC.resid , color = NDD)) + 
  geom_boxplot() + 
  facet_wrap(~FCtype)

```
## statistics diff weight - group
```{r, fig.width=12}
#using Anova (type 2 F tests [unique variance]) instead of aov (type 1 F test [sequential])

# fctype x dx
print(paste("Anova Table for fctype X NDD"))
F2 <- Anova(lm(Z ~ FCtype*NDD + Age + sex + Comp.1 + Comp.2, 
               data = simplified_pond))
print(F2)
F1 <-aov(Z ~ FCtype*NDD + Age + sex + Comp.1 + Comp.2, 
               data = simplified_pond)
print(TukeyHSD(x=F1, 'NDD', conf.level=0.95))
print(TukeyHSD(x=F1, 'FCtype', conf.level=0.95))

# plot fctype X dx
ggplot(simplified_pond, aes(x=FCtype, y=Z, color = NDD)) + 
  geom_boxplot() 

# fctype x dx (male only)
print(paste("Anova Table for fctype X NDD, male only"))
F2 <- Anova(lm(Z ~ FCtype*NDD + Age + Comp.1 + Comp.2, 
               data = filter(simplified_pond, sex == "Male")))
print(F2)
F1 <- aov(Z ~ FCtype*NDD + Age + Comp.1 + Comp.2, 
               data = filter(simplified_pond, sex == "Male"))
print(TukeyHSD(x=F1, 'NDD', conf.level=0.95))
print(TukeyHSD(x=F1, 'FCtype', conf.level=0.95))

# plot fctype X dx (male only)
ggplot(filter(simplified_pond, sex == "Male"), aes(x=FCtype, y=Z, color = NDD)) + 
  geom_boxplot() 

# dx per fctype
for (fctype in c('HE','HO','I')) {
  print(paste("Anova Table for",fctype))
  F2 <- Anova(lm(Z ~ NDD + Age + sex + Comp.1 + Comp.2, 
                 data = filter(simplified_pond, FCtype == fctype)))
  print(F2)
  F1 <- aov(Z ~ NDD + Age + sex + Comp.1 + Comp.2, 
                 data = filter(simplified_pond, FCtype == fctype))
  print(TukeyHSD(x=F1, 'NDD', conf.level=0.95))
}

#male only dx per fctype
for (fctype in c('HE','HO','I')) {
  print(paste("Anova Table for",fctype))
  F2 <- Anova(lm(Z ~ NDD + Age + Comp.1 + Comp.2, 
                 data = filter(simplified_pond, sex == "Male", FCtype == fctype)))
  print(F2)
  F1 <- aov(Z ~ NDD + Age + Comp.1 + Comp.2, 
                 data = filter(simplified_pond, sex == "Male", FCtype == fctype))
  print(TukeyHSD(x=F1, 'NDD', conf.level=0.95))
}


#for (fctype in c("CC01","CC02","CC03","CC04", "CC05","CC06","CC07","CC08","CC09", "CC10")) {
#  print(paste("Anova Table for",fctype))
#  a1 <- aov(Z ~ NDD + Age + Comp.1 + Comp.2, 
#                 data = filter(simplified_pond, sex == "Male", FCtype == fctype))
#  print(summary(a1))
#  print(TukeyHSD(x=a1, 'NDD', conf.level=0.95))
#}

#ggplot(filter(simplified_pond, FCtype %in% c("CC01","CC02","CC03","CC04", "CC05","CC06","CC07","CC08","CC09", "CC10")), 
#       aes(x=as.numeric(factor(FCtype)), y=Z , color = NDD)) + 
# geom_jitter(width = 0.5) + geom_smooth(span = 0.5) 

```

## statistics diff - Continuous measures
```{r, fig.width=12}
# ABAS_GC + SCQ + TOCS +FSIQ.x + AttnCBCLR

# fctype x general adaptive functioning
print(paste("Anova Table for fctype X NDD"))
F2 <- Anova(lm(Z ~ FCtype + ABAS_GC*TOCS*AttnCBCLR*SCQ + FSIQ + Age + sex + Comp.1 + Comp.2, 
               data = simplified_pond, na.action=na.omit))
print(F2)
F1 <- aov(Z ~ FCtype:NDD + FCtype:ABAS_GC +NDD:ABAS_GC +FCtype +NDD + ABAS_GC + Age + sex + Comp.1 + Comp.2, 
               data = simplified_pond)
print(TukeyHSD(x=F1, 'FCtype', conf.level=0.95))

# plot adaptive func by type and xx
ggplot(simplified_pond, aes(x=SCQ, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)


# fctype x dx (male only)
print(paste("Anova Table for fctype X NDD, male only"))
a1 <- aov(Z ~ FCtype*NDD*ABAS_GC + Age + Comp.1 + Comp.2, 
               data = filter(simplified_pond, sex == "Male"))
print(summary(a1))


# plot fctype X dx (male only)
ggplot(filter(simplified_pond, sex =="Male"), aes(x=ABAS_GC, y=Z, color = NDD)) + 
  geom_point() + geom_smooth(method = "lm") +
  facet_wrap(~FCtype)


####
# dx per fctype
for (fctype in c('HE','HO','I')) {
  print(paste("Anova Table for",fctype))
  a1 <- aov(Z ~ NDD + Age + sex + Comp.1 + Comp.2, 
                 data = filter(simplified_pond, FCtype == fctype))
  print(summary(a1))
  print(TukeyHSD(x=a1, 'NDD', conf.level=0.95))
}

#male only dx per fctype
for (fctype in c('HE','HO','I')) {
  print(paste("Anova Table for",fctype))
  a1 <- aov(Z ~ NDD + Age + Comp.1 + Comp.2, 
                 data = filter(simplified_pond, sex == "Male", FCtype == fctype))
  print(summary(a1))
  print(TukeyHSD(x=a1, 'NDD', conf.level=0.95))
}
```